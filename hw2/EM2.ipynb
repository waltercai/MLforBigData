{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal as mn\n",
    "from scipy.linalg import norm\n",
    "from scipy.misc import logsumexp\n",
    "import pprint\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def e_step(docs, log_prior, mu, sigma):\n",
    "    num_docs = len(docs)\n",
    "    K = len(mu)\n",
    "    log_resp = np.zeros(shape=[num_docs, K]);\n",
    "    for i in range(num_docs):\n",
    "        # fill in the raw values for the row corresponding to document i\n",
    "        for k in range(K):\n",
    "            log_prob = mn.logpdf(x=docs[i,:],\n",
    "                                 mean=mu[k,:],\n",
    "                                 cov=sigma[k,:,:])\n",
    "            log_resp[i,k] = log_prior[k] + log_prob\n",
    "        # normalize each row\n",
    "        log_row_sum = logsumexp(log_resp[i,:])\n",
    "        log_resp[i,:] -= log_row_sum\n",
    "    \n",
    "    return log_resp\n",
    "\n",
    "def m_step(log_resp, docs):\n",
    "    num_docs = len(docs)\n",
    "    K = len(log_resp[0,:])\n",
    "    dim = len(docs[0,:])\n",
    "    \n",
    "    log_prior = np.zeros(K)\n",
    "    mu = np.zeros(shape=[K,dim])\n",
    "    sigma = np.zeros(shape=[K, dim, dim])\n",
    "    \n",
    "    for k in range(K):\n",
    "        col_sum = np.sum(np.exp(log_resp[:,k]))\n",
    "        \n",
    "        # recalcuate prior\n",
    "        log_prior[k] = np.log(col_sum / num_docs)\n",
    "        \n",
    "        # recalculate mu\n",
    "        for i in range(num_docs):\n",
    "            mu[k,:] += np.exp(log_resp[i,k]) * docs[i,:]\n",
    "        mu[k,:] = mu[k,:] / col_sum\n",
    "    \n",
    "    for k in range(K):\n",
    "        col_sum = np.sum(np.exp(log_resp[:,k]))\n",
    "        \n",
    "        # recalculate sigma\n",
    "        for i in range(num_docs):\n",
    "            sigma[k,:,:] += np.exp(log_resp[i,k]) * np.outer(docs[i,:]-mu[k,:], docs[i,:]-mu[k,:])\n",
    "        sigma[k,:,:] /= col_sum\n",
    "        \n",
    "    lambduh = 0.2\n",
    "    sigma = (1 - lambduh) * sigma + lambduh * np.identity(dim)\n",
    "        \n",
    "    return [log_prior, mu, sigma]\n",
    "        \n",
    "def get_ll(log_resp, docs, log_prior, mu, sigma):\n",
    "    num_docs = len(docs)\n",
    "    K = len(mu)\n",
    "    \n",
    "    ll = 0.0\n",
    "    \n",
    "    for i in range(num_docs):\n",
    "        for k in range(K):\n",
    "            inner = log_prior[k] + mn.logpdf(x=docs[i,:],\n",
    "                                              mean=mu[k,:],\n",
    "                                              cov=sigma[k,:,:])\n",
    "            ll += np.exp(log_resp[i,k]) * inner\n",
    "    \n",
    "    return ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.24350533  3.21386328  2.0568074   1.92600899  0.        ]\n",
      " [ 0.          0.          0.          0.          3.61932839]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          2.0568074   0.          0.        ]\n",
      " [ 0.          0.          2.0568074   0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "num_docs = 0\n",
    "num_terms = 0\n",
    "term_total = 0\n",
    "K=5\n",
    "docs_dict = []\n",
    "\n",
    "with open(\"/Users/waltercai/Documents/cse547/hw2/bbc_data/bbc.mtx\") as mtx:\n",
    "    line_count = 0\n",
    "    for line in mtx:\n",
    "        line_count+=1\n",
    "        if line_count == 1:\n",
    "            pass\n",
    "        elif line_count == 2:\n",
    "            line_split = line.split(\" \")\n",
    "            num_terms = int(line_split[0])\n",
    "            num_docs = int(line_split[1])\n",
    "            term_total = int(line_split[2])\n",
    "            \n",
    "            for i in range(num_docs):\n",
    "                docs_dict.append({})\n",
    "            len(docs_dict)\n",
    "        else:\n",
    "            line_split = line.split(\" \")\n",
    "            # change to 0 indexing\n",
    "            term = int(line_split[0]) - 1\n",
    "            doc = int(line_split[1]) - 1\n",
    "            freq = float(line_split[2])\n",
    "            \n",
    "            docs_dict[doc][term] = freq\n",
    "\n",
    "\n",
    "    \n",
    "#                 labels.append(int(line_split[0]))\n",
    "\n",
    "tf = np.zeros(shape=[num_docs, num_terms])\n",
    "for i in range(num_docs):\n",
    "    for k in docs_dict[i].keys():\n",
    "        tf[i,k] = docs_dict[i][k]\n",
    "    tf[i,:] = tf[i,:] / np.max(tf[i,:])\n",
    "\n",
    "idf = np.zeros(num_terms)\n",
    "for t in range(num_terms):\n",
    "    idf[t] = np.log((num_docs + 0.0) / np.count_nonzero(tf[:,t]))\n",
    "    \n",
    "for t in range(num_terms):\n",
    "    tf[:,t] *= idf[t]\n",
    "\n",
    "tfidf = tf\n",
    "print(tfidf[0:5, 0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1\n",
      "iteration: 2\n",
      "iteration: 3\n",
      "iteration: 4\n",
      "iteration: 5\n"
     ]
    }
   ],
   "source": [
    "# get true classes\n",
    "true_label = []\n",
    "with open(\"/Users/waltercai/Documents/cse547/hw2/bbc_data/bbc.classes\") as classes:\n",
    "    for line in classes:\n",
    "        line_split = line.split(\" \")\n",
    "        true_label.append(int(line_split[1]))\n",
    "\n",
    "# initialize mu\n",
    "mu = np.zeros(shape=[K, num_terms])\n",
    "with open(\"/Users/waltercai/Documents/cse547/hw2/bbc_data/bbc.centers\") as centers:\n",
    "    line_count = 0\n",
    "    for line in centers:\n",
    "        line_split = line.split(\" \")\n",
    "        for t in range(num_terms):\n",
    "            mu[line_count, t] = float(line_split[t])\n",
    "        line_count+=1\n",
    "log_prior = np.log(np.zeros(K) + 1.0/K)\n",
    "log_resp = np.zeros(shape=[num_docs, K]);\n",
    "\n",
    "sigma = np.zeros(shape=[K, num_terms, num_terms])\n",
    "for k in range(K):\n",
    "    sigma[k,:,:] = np.identity(num_terms)\n",
    "\n",
    "old_ll = 0.0\n",
    "\n",
    "lls = []\n",
    "loss = []\n",
    "for i in range(5):\n",
    "    print(\"iteration: {}\".format(i+1))\n",
    "    log_resp = e_step(docs=tfidf, log_prior=log_prior, mu=mu, sigma=sigma)\n",
    "    [prior, mu, sigma] = m_step(log_resp=log_resp, docs=tfidf)\n",
    "    \n",
    "    guess_list = []\n",
    "    for i in range(num_docs):\n",
    "        k = np.argmax(np.exp(log_resp[i,:]))\n",
    "        guess_list.append(k)\n",
    "    loss.append(np.count_nonzero(np.array(guess_list) - np.array(true_label)))\n",
    "    \n",
    "    new_ll = get_ll(log_resp=log_resp, docs=tfidf, log_prior=log_prior, mu=mu, sigma=sigma)\n",
    "    lls.append(new_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log likelihoods: [-251609.2844170855, -146880.51802649521, -140381.1887159429, -138878.68767706116, -138063.42047029201]\n",
      "0/1 Loss: [649, 591, 547, 555, 522]\n",
      "num documents: 1791\n"
     ]
    }
   ],
   "source": [
    "# print(\"mu(s): {}\\n\".format(mu))\n",
    "# print(\"sigma(s): {}\\n\".format(sigma))\n",
    "guess = {}\n",
    "for k in range(K):\n",
    "    guess[k] = []\n",
    "for i in range(num_docs):\n",
    "    k = np.argmax(np.exp(log_resp[i,:]))\n",
    "    guess[k].append(i)\n",
    "# for k in range(K):\n",
    "#     print(\"guess cluster {}: {}\\n\".format(k, guess[k]))\n",
    "print(\"log likelihoods: {}\".format(lls))\n",
    "print(\"0/1 Loss: {}\".format(loss))\n",
    "print(\"num documents: {}\".format(num_docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
